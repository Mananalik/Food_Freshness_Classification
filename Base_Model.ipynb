{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mananalik/Food_Freshness_Classification/blob/main/Base_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VuxZevFi9C5G"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9YHSJK39IKJ",
        "outputId": "2de90f9e-2f1b-4ad0-fd83-01e2dc0af504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sensor dataset...\n",
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: mananjaat28\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/mehrabmahdian/food-freshness-electronic-nose-data\n",
            "Downloading food-freshness-electronic-nose-data.zip to ./food-freshness-electronic-nose-data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.81M/9.81M [00:00<00:00, 1.24GB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Sensor dataset downloaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "print(\"Downloading sensor dataset...\")\n",
        "od.download('https://www.kaggle.com/datasets/mehrabmahdian/food-freshness-electronic-nose-data')\n",
        "\n",
        "print(\"\\n✅ Sensor dataset downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPT8FslE9Ohv",
        "outputId": "293fb22b-4363-4cb7-8f34-173c7471ed0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q5OtqJgy9WLn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZK1lND2Z9YRH"
      },
      "outputs": [],
      "source": [
        "DATA_DIRECTORY = 'food-freshness-electronic-nose-data/AllSmaples-Report/'\n",
        "SENSOR_COLUMNS = ['MQ3', 'MQ8', 'MQ135']\n",
        "SEQUENCE_LENGTH = 180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xIs03NZd9b9t"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(data_dir, sensor_list, seq_len):\n",
        "    all_data = []\n",
        "    labels = []\n",
        "    freshness_mapping = {'D1': 0, 'D2': 1, 'D3': 2, 'D4': 3, 'D5': 4}\n",
        "\n",
        "    print(\"--- Loading and parsing data files ---\")\n",
        "    for filename in os.listdir(data_dir):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            parts = filename.replace('.csv', '').split(' ')\n",
        "            if len(parts) > 1 and parts[-1] in freshness_mapping:\n",
        "                label = freshness_mapping[parts[-1]]\n",
        "                filepath = os.path.join(data_dir, filename)\n",
        "                df = pd.read_csv(filepath)\n",
        "\n",
        "\n",
        "                if all(col in df.columns for col in sensor_list):\n",
        "                    df_sensors = df[sensor_list]\n",
        "\n",
        "                    step_size = 30\n",
        "                    for i in range(0, len(df_sensors) - seq_len + 1, step_size):\n",
        "                        sequence = df_sensors.iloc[i:i + seq_len].values\n",
        "                        all_data.append(sequence)\n",
        "                        labels.append(label)\n",
        "                else:\n",
        "                    print(f\"Skipping {filename}: does not contain all required sensors.\")\n",
        "            else:\n",
        "                print(f\"Skipping {filename}: unrecognized freshness label.\")\n",
        "\n",
        "    X_sequences = np.array(all_data)\n",
        "    y_labels = np.array(labels)\n",
        "    freshness_labels = {v: k for k, v in freshness_mapping.items()}\n",
        "\n",
        "    print(f\"\\nTotal sequences created: {len(X_sequences)}\")\n",
        "    return X_sequences, y_labels, freshness_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nbh4cyk99hPx"
      },
      "outputs": [],
      "source": [
        "def scale_data(X_train, X_test):\n",
        "    print(\"\\n--- Scaling data ---\")\n",
        "    n_features = X_train.shape[2]\n",
        "    X_train_reshaped = X_train.reshape(-1, n_features)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled_reshaped = scaler.fit_transform(X_train_reshaped)\n",
        "    X_train_scaled = X_train_scaled_reshaped.reshape(X_train.shape)\n",
        "\n",
        "    X_test_reshaped = X_test.reshape(-1, n_features)\n",
        "    X_test_scaled_reshaped = scaler.transform(X_test_reshaped)\n",
        "    X_test_scaled = X_test_scaled_reshaped.reshape(X_test.shape)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uNNtcaAF9jPQ"
      },
      "outputs": [],
      "source": [
        "def build_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=256, kernel_size=5, activation='relu', input_shape=input_shape, name=\"Conv1D_1\"),\n",
        "        MaxPooling1D(pool_size=2, name=\"MaxPool_1\"),\n",
        "        Dropout(0.4, name=\"Dropout_1\"),\n",
        "\n",
        "        LSTM(200, return_sequences=True, name=\"LSTM_1\"),\n",
        "        Dropout(0.4, name=\"Dropout_2\"),\n",
        "\n",
        "        LSTM(100, name=\"LSTM_2\"),\n",
        "        Dropout(0.4, name=\"Dropout_3\"),\n",
        "\n",
        "        Dense(100, activation='relu', name=\"Dense_1\"),\n",
        "        Dense(num_classes, activation='softmax', name=\"Output_Layer\")\n",
        "    ], name=\"Tuned_CNN_LSTM_Hybrid\")\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uaptrIGK9k-m",
        "outputId": "9ccffa46-6ce9-437c-9a89-97863b22dcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading and parsing data files ---\n",
            "Skipping Mandarin.csv: unrecognized freshness label.\n",
            "Skipping AppleBananaTomato.csv: unrecognized freshness label.\n",
            "Skipping AppleTomato.csv: unrecognized freshness label.\n",
            "Skipping AppleBanana.csv: unrecognized freshness label.\n",
            "Skipping AppleBananaMandarin.csv: unrecognized freshness label.\n",
            "Skipping TomatoBanana.csv: unrecognized freshness label.\n",
            "Skipping BananaMandarin.csv: unrecognized freshness label.\n",
            "Skipping TomatoMandarin.csv: unrecognized freshness label.\n",
            "Skipping AppleMandarin.csv: unrecognized freshness label.\n",
            "\n",
            "Total sequences created: 21613\n",
            "\n",
            "--- Scaling data ---\n",
            "✅ Scaler saved to 'time_series_scaler.pkl'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Tuned_CNN_LSTM_Hybrid\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Tuned_CNN_LSTM_Hybrid\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Conv1D_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m176\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ MaxPool_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ LSTM_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │       \u001b[38;5;34m365,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ LSTM_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m120,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m505\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Conv1D_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ MaxPool_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ LSTM_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">365,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ LSTM_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">505</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m500,701\u001b[0m (1.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,701</span> (1.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m500,701\u001b[0m (1.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,701</span> (1.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training CNN-LSTM Model ---\n",
            "Epoch 1/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.4518 - loss: 1.1923 - val_accuracy: 0.6660 - val_loss: 0.7420\n",
            "Epoch 2/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.6971 - loss: 0.7155 - val_accuracy: 0.8277 - val_loss: 0.4620\n",
            "Epoch 3/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.7961 - loss: 0.5315 - val_accuracy: 0.8508 - val_loss: 0.4023\n",
            "Epoch 4/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8389 - loss: 0.4405 - val_accuracy: 0.8552 - val_loss: 0.3674\n",
            "Epoch 5/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.8557 - loss: 0.4015 - val_accuracy: 0.8998 - val_loss: 0.2663\n",
            "Epoch 6/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8598 - loss: 0.3766 - val_accuracy: 0.8945 - val_loss: 0.2653\n",
            "Epoch 7/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.8799 - loss: 0.3286 - val_accuracy: 0.8917 - val_loss: 0.3026\n",
            "Epoch 8/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8780 - loss: 0.3266 - val_accuracy: 0.9075 - val_loss: 0.2438\n",
            "Epoch 9/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8962 - loss: 0.2717 - val_accuracy: 0.9202 - val_loss: 0.2176\n",
            "Epoch 10/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9062 - loss: 0.2544 - val_accuracy: 0.9216 - val_loss: 0.2077\n",
            "Epoch 11/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9164 - loss: 0.2356 - val_accuracy: 0.9311 - val_loss: 0.1924\n",
            "Epoch 12/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9149 - loss: 0.2237 - val_accuracy: 0.9449 - val_loss: 0.1598\n",
            "Epoch 13/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9283 - loss: 0.2021 - val_accuracy: 0.9077 - val_loss: 0.2329\n",
            "Epoch 14/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9292 - loss: 0.2105 - val_accuracy: 0.9482 - val_loss: 0.1266\n",
            "Epoch 15/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9451 - loss: 0.1658 - val_accuracy: 0.9244 - val_loss: 0.1959\n",
            "Epoch 16/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9402 - loss: 0.1776 - val_accuracy: 0.9498 - val_loss: 0.1308\n",
            "Epoch 17/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9299 - loss: 0.2012 - val_accuracy: 0.9528 - val_loss: 0.1344\n",
            "Epoch 18/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9423 - loss: 0.1804 - val_accuracy: 0.9468 - val_loss: 0.1349\n",
            "Epoch 19/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9398 - loss: 0.1809 - val_accuracy: 0.9526 - val_loss: 0.1561\n",
            "Epoch 20/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9453 - loss: 0.1499 - val_accuracy: 0.9560 - val_loss: 0.1165\n",
            "Epoch 21/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9501 - loss: 0.1373 - val_accuracy: 0.9160 - val_loss: 0.2790\n",
            "Epoch 22/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9525 - loss: 0.1422 - val_accuracy: 0.9565 - val_loss: 0.1288\n",
            "Epoch 23/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9459 - loss: 0.1629 - val_accuracy: 0.9463 - val_loss: 0.1482\n",
            "Epoch 24/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9495 - loss: 0.1418 - val_accuracy: 0.9537 - val_loss: 0.1223\n",
            "Epoch 25/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9470 - loss: 0.1580 - val_accuracy: 0.9704 - val_loss: 0.0908\n",
            "Epoch 26/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9558 - loss: 0.1343 - val_accuracy: 0.9676 - val_loss: 0.0813\n",
            "Epoch 27/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9579 - loss: 0.1105 - val_accuracy: 0.9544 - val_loss: 0.1547\n",
            "Epoch 28/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9498 - loss: 0.1492 - val_accuracy: 0.9667 - val_loss: 0.0888\n",
            "Epoch 29/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9662 - loss: 0.0991 - val_accuracy: 0.9660 - val_loss: 0.0781\n",
            "Epoch 30/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9612 - loss: 0.1062 - val_accuracy: 0.9787 - val_loss: 0.0574\n",
            "Epoch 31/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9680 - loss: 0.0912 - val_accuracy: 0.9704 - val_loss: 0.0782\n",
            "Epoch 32/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9620 - loss: 0.1039 - val_accuracy: 0.9750 - val_loss: 0.0778\n",
            "Epoch 33/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9659 - loss: 0.1012 - val_accuracy: 0.9766 - val_loss: 0.0729\n",
            "Epoch 34/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9665 - loss: 0.1013 - val_accuracy: 0.9702 - val_loss: 0.0806\n",
            "Epoch 35/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9685 - loss: 0.0870 - val_accuracy: 0.9780 - val_loss: 0.0660\n",
            "Epoch 36/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9737 - loss: 0.0804 - val_accuracy: 0.9651 - val_loss: 0.0729\n",
            "Epoch 37/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9613 - loss: 0.1093 - val_accuracy: 0.9771 - val_loss: 0.0707\n",
            "Epoch 38/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9686 - loss: 0.0928 - val_accuracy: 0.9655 - val_loss: 0.0855\n",
            "Epoch 39/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9658 - loss: 0.0960 - val_accuracy: 0.9739 - val_loss: 0.0692\n",
            "Epoch 40/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9706 - loss: 0.0868 - val_accuracy: 0.9824 - val_loss: 0.0538\n",
            "Epoch 41/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9699 - loss: 0.0853 - val_accuracy: 0.9426 - val_loss: 0.1871\n",
            "Epoch 42/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9603 - loss: 0.1215 - val_accuracy: 0.9833 - val_loss: 0.0509\n",
            "Epoch 43/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9716 - loss: 0.0794 - val_accuracy: 0.9556 - val_loss: 0.1224\n",
            "Epoch 44/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9619 - loss: 0.1110 - val_accuracy: 0.9759 - val_loss: 0.0666\n",
            "Epoch 45/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9709 - loss: 0.0798 - val_accuracy: 0.9815 - val_loss: 0.0475\n",
            "Epoch 46/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9697 - loss: 0.0871 - val_accuracy: 0.9739 - val_loss: 0.0760\n",
            "Epoch 47/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9740 - loss: 0.0701 - val_accuracy: 0.9773 - val_loss: 0.0707\n",
            "Epoch 48/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9638 - loss: 0.1067 - val_accuracy: 0.9789 - val_loss: 0.0570\n",
            "Epoch 49/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9720 - loss: 0.0815 - val_accuracy: 0.9500 - val_loss: 0.1753\n",
            "Epoch 50/50\n",
            "\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9651 - loss: 0.1016 - val_accuracy: 0.9646 - val_loss: 0.0995\n",
            "\n",
            "🎯 Final Model Accuracy: 98.15%\n",
            "✅ Label mapping saved to 'freshness_labels.json'\n",
            "\n",
            "--- Project Complete! ---\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "\n",
        "    X, y_raw, freshness_labels = load_and_preprocess_data(DATA_DIRECTORY, SENSOR_COLUMNS, SEQUENCE_LENGTH)\n",
        "\n",
        "\n",
        "    num_classes = len(np.unique(y_raw))\n",
        "    y_one_hot = tf.keras.utils.to_categorical(y_raw, num_classes=num_classes)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42, stratify=y_raw)\n",
        "\n",
        "    X_train_scaled, X_test_scaled, scaler = scale_data(X_train, X_test)\n",
        "    joblib.dump(scaler, 'time_series_scaler.pkl')\n",
        "    print(\"✅ Scaler saved to 'time_series_scaler.pkl'\")\n",
        "\n",
        "\n",
        "    input_shape = (X_train_scaled.shape[1], X_train_scaled.shape[2])\n",
        "    model = build_cnn_lstm_model(input_shape, num_classes)\n",
        "    model.summary()\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
        "        ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Training CNN-LSTM Model ---\")\n",
        "    history = model.fit(\n",
        "        X_train_scaled, y_train,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test_scaled, y_test),\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "\n",
        "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "    print(f\"\\n🎯 Final Model Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "    with open('freshness_labels.json', 'w') as f:\n",
        "        json.dump(freshness_labels, f)\n",
        "    print(\"✅ Label mapping saved to 'freshness_labels.json'\")\n",
        "    print(\"\\n--- Project Complete! ---\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLrGjbid9xDe",
        "outputId": "1472ebbc-e1f9-4dbf-9827-c7dc8ef73dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test dataset - Sheet1.csv...\n",
            "✅ Successfully created challenge.csv with 1080 rows.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# --- Settings ---\n",
        "START_ROW = 4500\n",
        "END_ROW = 5580\n",
        "# V V V THIS IS THE LINE I CHANGED V V V\n",
        "INPUT_FILE = \"test dataset - Sheet1.csv\" # Use the exact name of the file you uploaded\n",
        "OUTPUT_FILE = \"challenge.csv\"\n",
        "# ---\n",
        "\n",
        "# We don't need to upload again if the file is already there\n",
        "try:\n",
        "    print(f\"Loading {INPUT_FILE}...\")\n",
        "    full_live_data = pd.read_csv(INPUT_FILE)\n",
        "\n",
        "    if len(full_live_data) >= END_ROW:\n",
        "        challenge_data = full_live_data.iloc[START_ROW:END_ROW]\n",
        "        challenge_data.to_csv(OUTPUT_FILE, index=False)\n",
        "        print(f\"✅ Successfully created {OUTPUT_FILE} with {len(challenge_data)} rows.\")\n",
        "    else:\n",
        "        print(f\"❌ Error: The file {INPUT_FILE} is too short.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: Could not find the file {INPUT_FILE}.\")\n",
        "    print(\"Please try uploading the file again in the cell above.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShjRJll6-_1x",
        "outputId": "af3ef2b1-5fd8-4940-c108-8023bb424e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Starting confidence test for: best_model.keras\n",
            "✅ Successfully loaded model and helpers.\n",
            "📄 Loaded 'test dataset - Sheet1.csv' with 12879 readings.\n",
            "--- Analysis (Window: 180, Step: 60) ---\n",
            "Chunk (Readings 0 to 179):\n",
            " ➡️ D5 (Confidence: 95.74%)\n",
            "    Runner-up: D4 (Confidence: 4.14%)\n",
            "Chunk (Readings 60 to 239):\n",
            " ➡️ D5 (Confidence: 95.70%)\n",
            "    Runner-up: D4 (Confidence: 4.17%)\n",
            "Chunk (Readings 120 to 299):\n",
            " ➡️ D5 (Confidence: 95.68%)\n",
            "    Runner-up: D4 (Confidence: 4.19%)\n",
            "Chunk (Readings 180 to 359):\n",
            " ➡️ D5 (Confidence: 95.67%)\n",
            "    Runner-up: D4 (Confidence: 4.19%)\n",
            "Chunk (Readings 240 to 419):\n",
            " ➡️ D5 (Confidence: 95.57%)\n",
            "    Runner-up: D4 (Confidence: 4.27%)\n",
            "Chunk (Readings 300 to 479):\n",
            " ➡️ D5 (Confidence: 95.59%)\n",
            "    Runner-up: D4 (Confidence: 4.26%)\n",
            "Chunk (Readings 360 to 539):\n",
            " ➡️ D5 (Confidence: 95.49%)\n",
            "    Runner-up: D4 (Confidence: 4.34%)\n",
            "Chunk (Readings 420 to 599):\n",
            " ➡️ D5 (Confidence: 95.45%)\n",
            "    Runner-up: D4 (Confidence: 4.36%)\n",
            "Chunk (Readings 480 to 659):\n",
            " ➡️ D5 (Confidence: 95.41%)\n",
            "    Runner-up: D4 (Confidence: 4.41%)\n",
            "Chunk (Readings 540 to 719):\n",
            " ➡️ D5 (Confidence: 95.25%)\n",
            "    Runner-up: D4 (Confidence: 4.57%)\n",
            "Chunk (Readings 600 to 779):\n",
            " ➡️ D5 (Confidence: 95.30%)\n",
            "    Runner-up: D4 (Confidence: 4.53%)\n",
            "Chunk (Readings 660 to 839):\n",
            " ➡️ D5 (Confidence: 95.28%)\n",
            "    Runner-up: D4 (Confidence: 4.55%)\n",
            "Chunk (Readings 720 to 899):\n",
            " ➡️ D5 (Confidence: 95.29%)\n",
            "    Runner-up: D4 (Confidence: 4.55%)\n",
            "Chunk (Readings 780 to 959):\n",
            " ➡️ D5 (Confidence: 95.30%)\n",
            "    Runner-up: D4 (Confidence: 4.53%)\n",
            "Chunk (Readings 840 to 1019):\n",
            " ➡️ D5 (Confidence: 95.28%)\n",
            "    Runner-up: D4 (Confidence: 4.56%)\n",
            "Chunk (Readings 900 to 1079):\n",
            " ➡️ D5 (Confidence: 95.34%)\n",
            "    Runner-up: D4 (Confidence: 4.51%)\n",
            "Chunk (Readings 960 to 1139):\n",
            " ➡️ D5 (Confidence: 95.35%)\n",
            "    Runner-up: D4 (Confidence: 4.50%)\n",
            "Chunk (Readings 1020 to 1199):\n",
            " ➡️ D5 (Confidence: 95.33%)\n",
            "    Runner-up: D4 (Confidence: 4.51%)\n",
            "Chunk (Readings 1080 to 1259):\n",
            " ➡️ D5 (Confidence: 95.35%)\n",
            "    Runner-up: D4 (Confidence: 4.49%)\n",
            "Chunk (Readings 1140 to 1319):\n",
            " ➡️ D5 (Confidence: 95.31%)\n",
            "    Runner-up: D4 (Confidence: 4.52%)\n",
            "Chunk (Readings 1200 to 1379):\n",
            " ➡️ D5 (Confidence: 95.31%)\n",
            "    Runner-up: D4 (Confidence: 4.52%)\n",
            "Chunk (Readings 1260 to 1439):\n",
            " ➡️ D5 (Confidence: 95.32%)\n",
            "    Runner-up: D4 (Confidence: 4.50%)\n",
            "Chunk (Readings 1320 to 1499):\n",
            " ➡️ D5 (Confidence: 95.32%)\n",
            "    Runner-up: D4 (Confidence: 4.49%)\n",
            "Chunk (Readings 1380 to 1559):\n",
            " ➡️ D5 (Confidence: 95.30%)\n",
            "    Runner-up: D4 (Confidence: 4.51%)\n",
            "Chunk (Readings 1440 to 1619):\n",
            " ➡️ D5 (Confidence: 95.32%)\n",
            "    Runner-up: D4 (Confidence: 4.49%)\n",
            "Chunk (Readings 1500 to 1679):\n",
            " ➡️ D5 (Confidence: 95.34%)\n",
            "    Runner-up: D4 (Confidence: 4.47%)\n",
            "Chunk (Readings 1560 to 1739):\n",
            " ➡️ D5 (Confidence: 95.35%)\n",
            "    Runner-up: D4 (Confidence: 4.46%)\n",
            "Chunk (Readings 1620 to 1799):\n",
            " ➡️ D5 (Confidence: 95.38%)\n",
            "    Runner-up: D4 (Confidence: 4.43%)\n",
            "Chunk (Readings 1680 to 1859):\n",
            " ➡️ D5 (Confidence: 95.39%)\n",
            "    Runner-up: D4 (Confidence: 4.42%)\n",
            "Chunk (Readings 1740 to 1919):\n",
            " ➡️ D5 (Confidence: 95.41%)\n",
            "    Runner-up: D4 (Confidence: 4.39%)\n",
            "Chunk (Readings 1800 to 1979):\n",
            " ➡️ D5 (Confidence: 95.42%)\n",
            "    Runner-up: D4 (Confidence: 4.38%)\n",
            "Chunk (Readings 1860 to 2039):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.38%)\n",
            "Chunk (Readings 1920 to 2099):\n",
            " ➡️ D5 (Confidence: 95.45%)\n",
            "    Runner-up: D4 (Confidence: 4.35%)\n",
            "Chunk (Readings 1980 to 2159):\n",
            " ➡️ D5 (Confidence: 95.44%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 2040 to 2219):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.38%)\n",
            "Chunk (Readings 2100 to 2279):\n",
            " ➡️ D5 (Confidence: 95.41%)\n",
            "    Runner-up: D4 (Confidence: 4.40%)\n",
            "Chunk (Readings 2160 to 2339):\n",
            " ➡️ D5 (Confidence: 95.39%)\n",
            "    Runner-up: D4 (Confidence: 4.42%)\n",
            "Chunk (Readings 2220 to 2399):\n",
            " ➡️ D5 (Confidence: 95.44%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 2280 to 2459):\n",
            " ➡️ D5 (Confidence: 95.41%)\n",
            "    Runner-up: D4 (Confidence: 4.40%)\n",
            "Chunk (Readings 2340 to 2519):\n",
            " ➡️ D5 (Confidence: 95.46%)\n",
            "    Runner-up: D4 (Confidence: 4.35%)\n",
            "Chunk (Readings 2400 to 2579):\n",
            " ➡️ D5 (Confidence: 95.48%)\n",
            "    Runner-up: D4 (Confidence: 4.33%)\n",
            "Chunk (Readings 2460 to 2639):\n",
            " ➡️ D5 (Confidence: 95.47%)\n",
            "    Runner-up: D4 (Confidence: 4.34%)\n",
            "Chunk (Readings 2520 to 2699):\n",
            " ➡️ D5 (Confidence: 95.49%)\n",
            "    Runner-up: D4 (Confidence: 4.33%)\n",
            "Chunk (Readings 2580 to 2759):\n",
            " ➡️ D5 (Confidence: 95.45%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 2640 to 2819):\n",
            " ➡️ D5 (Confidence: 95.46%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 2700 to 2879):\n",
            " ➡️ D5 (Confidence: 95.45%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 2760 to 2939):\n",
            " ➡️ D5 (Confidence: 95.48%)\n",
            "    Runner-up: D4 (Confidence: 4.36%)\n",
            "Chunk (Readings 2820 to 2999):\n",
            " ➡️ D5 (Confidence: 95.50%)\n",
            "    Runner-up: D4 (Confidence: 4.33%)\n",
            "Chunk (Readings 2880 to 3059):\n",
            " ➡️ D5 (Confidence: 95.50%)\n",
            "    Runner-up: D4 (Confidence: 4.33%)\n",
            "Chunk (Readings 2940 to 3119):\n",
            " ➡️ D5 (Confidence: 95.53%)\n",
            "    Runner-up: D4 (Confidence: 4.31%)\n",
            "Chunk (Readings 3000 to 3179):\n",
            " ➡️ D5 (Confidence: 95.56%)\n",
            "    Runner-up: D4 (Confidence: 4.28%)\n",
            "Chunk (Readings 3060 to 3239):\n",
            " ➡️ D5 (Confidence: 95.42%)\n",
            "    Runner-up: D4 (Confidence: 4.40%)\n",
            "Chunk (Readings 3120 to 3299):\n",
            " ➡️ D5 (Confidence: 95.44%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 3180 to 3359):\n",
            " ➡️ D5 (Confidence: 95.41%)\n",
            "    Runner-up: D4 (Confidence: 4.41%)\n",
            "Chunk (Readings 3240 to 3419):\n",
            " ➡️ D5 (Confidence: 95.45%)\n",
            "    Runner-up: D4 (Confidence: 4.39%)\n",
            "Chunk (Readings 3300 to 3479):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.42%)\n",
            "Chunk (Readings 3360 to 3539):\n",
            " ➡️ D5 (Confidence: 95.47%)\n",
            "    Runner-up: D4 (Confidence: 4.38%)\n",
            "Chunk (Readings 3420 to 3599):\n",
            " ➡️ D5 (Confidence: 95.52%)\n",
            "    Runner-up: D4 (Confidence: 4.33%)\n",
            "Chunk (Readings 3480 to 3659):\n",
            " ➡️ D5 (Confidence: 95.48%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 3540 to 3719):\n",
            " ➡️ D5 (Confidence: 95.47%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 3600 to 3779):\n",
            " ➡️ D5 (Confidence: 95.44%)\n",
            "    Runner-up: D4 (Confidence: 4.39%)\n",
            "Chunk (Readings 3660 to 3839):\n",
            " ➡️ D5 (Confidence: 95.41%)\n",
            "    Runner-up: D4 (Confidence: 4.41%)\n",
            "Chunk (Readings 3720 to 3899):\n",
            " ➡️ D5 (Confidence: 95.39%)\n",
            "    Runner-up: D4 (Confidence: 4.43%)\n",
            "Chunk (Readings 3780 to 3959):\n",
            " ➡️ D5 (Confidence: 95.37%)\n",
            "    Runner-up: D4 (Confidence: 4.44%)\n",
            "Chunk (Readings 3840 to 4019):\n",
            " ➡️ D5 (Confidence: 95.28%)\n",
            "    Runner-up: D4 (Confidence: 4.55%)\n",
            "Chunk (Readings 3900 to 4079):\n",
            " ➡️ D5 (Confidence: 95.34%)\n",
            "    Runner-up: D4 (Confidence: 4.49%)\n",
            "Chunk (Readings 3960 to 4139):\n",
            " ➡️ D5 (Confidence: 95.32%)\n",
            "    Runner-up: D4 (Confidence: 4.51%)\n",
            "Chunk (Readings 4020 to 4199):\n",
            " ➡️ D5 (Confidence: 95.31%)\n",
            "    Runner-up: D4 (Confidence: 4.54%)\n",
            "Chunk (Readings 4080 to 4259):\n",
            " ➡️ D5 (Confidence: 95.37%)\n",
            "    Runner-up: D4 (Confidence: 4.48%)\n",
            "Chunk (Readings 4140 to 4319):\n",
            " ➡️ D5 (Confidence: 95.44%)\n",
            "    Runner-up: D4 (Confidence: 4.42%)\n",
            "Chunk (Readings 4200 to 4379):\n",
            " ➡️ D5 (Confidence: 95.49%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 4260 to 4439):\n",
            " ➡️ D5 (Confidence: 95.46%)\n",
            "    Runner-up: D4 (Confidence: 4.40%)\n",
            "Chunk (Readings 4320 to 4499):\n",
            " ➡️ D5 (Confidence: 95.51%)\n",
            "    Runner-up: D4 (Confidence: 4.36%)\n",
            "Chunk (Readings 4380 to 4559):\n",
            " ➡️ D5 (Confidence: 95.52%)\n",
            "    Runner-up: D4 (Confidence: 4.34%)\n",
            "Chunk (Readings 4440 to 4619):\n",
            " ➡️ D5 (Confidence: 95.49%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 4500 to 4679):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.44%)\n",
            "Chunk (Readings 4560 to 4739):\n",
            " ➡️ D5 (Confidence: 95.57%)\n",
            "    Runner-up: D4 (Confidence: 4.31%)\n",
            "Chunk (Readings 4620 to 4799):\n",
            " ➡️ D5 (Confidence: 95.60%)\n",
            "    Runner-up: D4 (Confidence: 4.28%)\n",
            "Chunk (Readings 4680 to 4859):\n",
            " ➡️ D5 (Confidence: 95.61%)\n",
            "    Runner-up: D4 (Confidence: 4.27%)\n",
            "Chunk (Readings 4740 to 4919):\n",
            " ➡️ D5 (Confidence: 95.61%)\n",
            "    Runner-up: D4 (Confidence: 4.27%)\n",
            "Chunk (Readings 4800 to 4979):\n",
            " ➡️ D5 (Confidence: 95.56%)\n",
            "    Runner-up: D4 (Confidence: 4.31%)\n",
            "Chunk (Readings 4860 to 5039):\n",
            " ➡️ D5 (Confidence: 95.47%)\n",
            "    Runner-up: D4 (Confidence: 4.39%)\n",
            "Chunk (Readings 4920 to 5099):\n",
            " ➡️ D5 (Confidence: 95.48%)\n",
            "    Runner-up: D4 (Confidence: 4.38%)\n",
            "Chunk (Readings 4980 to 5159):\n",
            " ➡️ D5 (Confidence: 95.51%)\n",
            "    Runner-up: D4 (Confidence: 4.35%)\n",
            "Chunk (Readings 5040 to 5219):\n",
            " ➡️ D5 (Confidence: 95.58%)\n",
            "    Runner-up: D4 (Confidence: 4.29%)\n",
            "Chunk (Readings 5100 to 5279):\n",
            " ➡️ D5 (Confidence: 95.35%)\n",
            "    Runner-up: D4 (Confidence: 4.53%)\n",
            "Chunk (Readings 5160 to 5339):\n",
            " ➡️ D5 (Confidence: 93.03%)\n",
            "    Runner-up: D4 (Confidence: 6.76%)\n",
            "Chunk (Readings 5220 to 5399):\n",
            " ➡️ D5 (Confidence: 91.76%)\n",
            "    Runner-up: D4 (Confidence: 7.85%)\n",
            "Chunk (Readings 5280 to 5459):\n",
            " ➡️ D5 (Confidence: 92.59%)\n",
            "    Runner-up: D4 (Confidence: 7.07%)\n",
            "Chunk (Readings 5340 to 5519):\n",
            " ➡️ D5 (Confidence: 91.71%)\n",
            "    Runner-up: D4 (Confidence: 7.89%)\n",
            "Chunk (Readings 5400 to 5579):\n",
            " ➡️ D5 (Confidence: 91.46%)\n",
            "    Runner-up: D4 (Confidence: 8.09%)\n",
            "Chunk (Readings 5460 to 5639):\n",
            " ➡️ D5 (Confidence: 91.15%)\n",
            "    Runner-up: D4 (Confidence: 8.30%)\n",
            "Chunk (Readings 5520 to 5699):\n",
            " ➡️ D5 (Confidence: 91.21%)\n",
            "    Runner-up: D4 (Confidence: 8.25%)\n",
            "Chunk (Readings 5580 to 5759):\n",
            " ➡️ D5 (Confidence: 91.32%)\n",
            "    Runner-up: D4 (Confidence: 8.16%)\n",
            "Chunk (Readings 5640 to 5819):\n",
            " ➡️ D5 (Confidence: 91.21%)\n",
            "    Runner-up: D4 (Confidence: 8.26%)\n",
            "Chunk (Readings 5700 to 5879):\n",
            " ➡️ D5 (Confidence: 91.17%)\n",
            "    Runner-up: D4 (Confidence: 8.28%)\n",
            "Chunk (Readings 5760 to 5939):\n",
            " ➡️ D5 (Confidence: 91.10%)\n",
            "    Runner-up: D4 (Confidence: 8.32%)\n",
            "Chunk (Readings 5820 to 5999):\n",
            " ➡️ D5 (Confidence: 91.00%)\n",
            "    Runner-up: D4 (Confidence: 8.41%)\n",
            "Chunk (Readings 5880 to 6059):\n",
            " ➡️ D5 (Confidence: 91.12%)\n",
            "    Runner-up: D4 (Confidence: 8.30%)\n",
            "Chunk (Readings 5940 to 6119):\n",
            " ➡️ D5 (Confidence: 91.14%)\n",
            "    Runner-up: D4 (Confidence: 8.30%)\n",
            "Chunk (Readings 6000 to 6179):\n",
            " ➡️ D5 (Confidence: 91.15%)\n",
            "    Runner-up: D4 (Confidence: 8.29%)\n",
            "Chunk (Readings 6060 to 6239):\n",
            " ➡️ D5 (Confidence: 91.20%)\n",
            "    Runner-up: D4 (Confidence: 8.24%)\n",
            "Chunk (Readings 6120 to 6299):\n",
            " ➡️ D5 (Confidence: 91.28%)\n",
            "    Runner-up: D4 (Confidence: 8.17%)\n",
            "Chunk (Readings 6180 to 6359):\n",
            " ➡️ D5 (Confidence: 91.26%)\n",
            "    Runner-up: D4 (Confidence: 8.19%)\n",
            "Chunk (Readings 6240 to 6419):\n",
            " ➡️ D5 (Confidence: 91.15%)\n",
            "    Runner-up: D4 (Confidence: 8.28%)\n",
            "Chunk (Readings 6300 to 6479):\n",
            " ➡️ D5 (Confidence: 91.14%)\n",
            "    Runner-up: D4 (Confidence: 8.29%)\n",
            "Chunk (Readings 6360 to 6539):\n",
            " ➡️ D5 (Confidence: 91.12%)\n",
            "    Runner-up: D4 (Confidence: 8.31%)\n",
            "Chunk (Readings 6420 to 6599):\n",
            " ➡️ D5 (Confidence: 91.02%)\n",
            "    Runner-up: D4 (Confidence: 8.39%)\n",
            "Chunk (Readings 6480 to 6659):\n",
            " ➡️ D5 (Confidence: 91.01%)\n",
            "    Runner-up: D4 (Confidence: 8.39%)\n",
            "Chunk (Readings 6540 to 6719):\n",
            " ➡️ D5 (Confidence: 91.04%)\n",
            "    Runner-up: D4 (Confidence: 8.36%)\n",
            "Chunk (Readings 6600 to 6779):\n",
            " ➡️ D5 (Confidence: 91.24%)\n",
            "    Runner-up: D4 (Confidence: 8.18%)\n",
            "Chunk (Readings 6660 to 6839):\n",
            " ➡️ D5 (Confidence: 91.36%)\n",
            "    Runner-up: D4 (Confidence: 8.11%)\n",
            "Chunk (Readings 6720 to 6899):\n",
            " ➡️ D5 (Confidence: 91.56%)\n",
            "    Runner-up: D4 (Confidence: 7.93%)\n",
            "Chunk (Readings 6780 to 6959):\n",
            " ➡️ D5 (Confidence: 92.43%)\n",
            "    Runner-up: D4 (Confidence: 7.15%)\n",
            "Chunk (Readings 6840 to 7019):\n",
            " ➡️ D5 (Confidence: 94.16%)\n",
            "    Runner-up: D4 (Confidence: 5.61%)\n",
            "Chunk (Readings 6900 to 7079):\n",
            " ➡️ D5 (Confidence: 95.15%)\n",
            "    Runner-up: D4 (Confidence: 4.71%)\n",
            "Chunk (Readings 6960 to 7139):\n",
            " ➡️ D5 (Confidence: 95.40%)\n",
            "    Runner-up: D4 (Confidence: 4.47%)\n",
            "Chunk (Readings 7020 to 7199):\n",
            " ➡️ D5 (Confidence: 94.87%)\n",
            "    Runner-up: D4 (Confidence: 4.98%)\n",
            "Chunk (Readings 7080 to 7259):\n",
            " ➡️ D5 (Confidence: 93.51%)\n",
            "    Runner-up: D4 (Confidence: 6.27%)\n",
            "Chunk (Readings 7140 to 7319):\n",
            " ➡️ D5 (Confidence: 92.51%)\n",
            "    Runner-up: D4 (Confidence: 7.14%)\n",
            "Chunk (Readings 7200 to 7379):\n",
            " ➡️ D5 (Confidence: 92.84%)\n",
            "    Runner-up: D4 (Confidence: 6.81%)\n",
            "Chunk (Readings 7260 to 7439):\n",
            " ➡️ D5 (Confidence: 93.65%)\n",
            "    Runner-up: D4 (Confidence: 6.08%)\n",
            "Chunk (Readings 7320 to 7499):\n",
            " ➡️ D5 (Confidence: 95.28%)\n",
            "    Runner-up: D4 (Confidence: 4.57%)\n",
            "Chunk (Readings 7380 to 7559):\n",
            " ➡️ D5 (Confidence: 95.42%)\n",
            "    Runner-up: D4 (Confidence: 4.44%)\n",
            "Chunk (Readings 7440 to 7619):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.43%)\n",
            "Chunk (Readings 7500 to 7679):\n",
            " ➡️ D5 (Confidence: 95.38%)\n",
            "    Runner-up: D4 (Confidence: 4.48%)\n",
            "Chunk (Readings 7560 to 7739):\n",
            " ➡️ D5 (Confidence: 95.39%)\n",
            "    Runner-up: D4 (Confidence: 4.47%)\n",
            "Chunk (Readings 7620 to 7799):\n",
            " ➡️ D5 (Confidence: 95.41%)\n",
            "    Runner-up: D4 (Confidence: 4.45%)\n",
            "Chunk (Readings 7680 to 7859):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.43%)\n",
            "Chunk (Readings 7740 to 7919):\n",
            " ➡️ D5 (Confidence: 95.38%)\n",
            "    Runner-up: D4 (Confidence: 4.48%)\n",
            "Chunk (Readings 7800 to 7979):\n",
            " ➡️ D5 (Confidence: 95.37%)\n",
            "    Runner-up: D4 (Confidence: 4.49%)\n",
            "Chunk (Readings 7860 to 8039):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.43%)\n",
            "Chunk (Readings 7920 to 8099):\n",
            " ➡️ D5 (Confidence: 95.44%)\n",
            "    Runner-up: D4 (Confidence: 4.42%)\n",
            "Chunk (Readings 7980 to 8159):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.43%)\n",
            "Chunk (Readings 8040 to 8219):\n",
            " ➡️ D5 (Confidence: 95.39%)\n",
            "    Runner-up: D4 (Confidence: 4.47%)\n",
            "Chunk (Readings 8100 to 8279):\n",
            " ➡️ D5 (Confidence: 95.37%)\n",
            "    Runner-up: D4 (Confidence: 4.48%)\n",
            "Chunk (Readings 8160 to 8339):\n",
            " ➡️ D5 (Confidence: 95.37%)\n",
            "    Runner-up: D4 (Confidence: 4.48%)\n",
            "Chunk (Readings 8220 to 8399):\n",
            " ➡️ D5 (Confidence: 95.37%)\n",
            "    Runner-up: D4 (Confidence: 4.49%)\n",
            "Chunk (Readings 8280 to 8459):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.42%)\n",
            "Chunk (Readings 8340 to 8519):\n",
            " ➡️ D5 (Confidence: 95.40%)\n",
            "    Runner-up: D4 (Confidence: 4.45%)\n",
            "Chunk (Readings 8400 to 8579):\n",
            " ➡️ D5 (Confidence: 95.40%)\n",
            "    Runner-up: D4 (Confidence: 4.45%)\n",
            "Chunk (Readings 8460 to 8639):\n",
            " ➡️ D5 (Confidence: 95.37%)\n",
            "    Runner-up: D4 (Confidence: 4.48%)\n",
            "Chunk (Readings 8520 to 8699):\n",
            " ➡️ D5 (Confidence: 95.44%)\n",
            "    Runner-up: D4 (Confidence: 4.42%)\n",
            "Chunk (Readings 8580 to 8759):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.43%)\n",
            "Chunk (Readings 8640 to 8819):\n",
            " ➡️ D5 (Confidence: 95.43%)\n",
            "    Runner-up: D4 (Confidence: 4.43%)\n",
            "Chunk (Readings 8700 to 8879):\n",
            " ➡️ D5 (Confidence: 95.52%)\n",
            "    Runner-up: D4 (Confidence: 4.34%)\n",
            "Chunk (Readings 8760 to 8939):\n",
            " ➡️ D5 (Confidence: 95.53%)\n",
            "    Runner-up: D4 (Confidence: 4.34%)\n",
            "Chunk (Readings 8820 to 8999):\n",
            " ➡️ D5 (Confidence: 95.56%)\n",
            "    Runner-up: D4 (Confidence: 4.31%)\n",
            "Chunk (Readings 8880 to 9059):\n",
            " ➡️ D5 (Confidence: 95.57%)\n",
            "    Runner-up: D4 (Confidence: 4.30%)\n",
            "Chunk (Readings 8940 to 9119):\n",
            " ➡️ D5 (Confidence: 94.71%)\n",
            "    Runner-up: D4 (Confidence: 5.13%)\n",
            "Chunk (Readings 9000 to 9179):\n",
            " ➡️ D5 (Confidence: 93.80%)\n",
            "    Runner-up: D4 (Confidence: 5.99%)\n",
            "Chunk (Readings 9060 to 9239):\n",
            " ➡️ D5 (Confidence: 93.85%)\n",
            "    Runner-up: D4 (Confidence: 5.93%)\n",
            "Chunk (Readings 9120 to 9299):\n",
            " ➡️ D5 (Confidence: 93.77%)\n",
            "    Runner-up: D4 (Confidence: 6.01%)\n",
            "Chunk (Readings 9180 to 9359):\n",
            " ➡️ D5 (Confidence: 93.51%)\n",
            "    Runner-up: D4 (Confidence: 6.23%)\n",
            "Chunk (Readings 9240 to 9419):\n",
            " ➡️ D5 (Confidence: 94.24%)\n",
            "    Runner-up: D4 (Confidence: 5.56%)\n",
            "Chunk (Readings 9300 to 9479):\n",
            " ➡️ D5 (Confidence: 93.98%)\n",
            "    Runner-up: D4 (Confidence: 5.82%)\n",
            "Chunk (Readings 9360 to 9539):\n",
            " ➡️ D5 (Confidence: 93.27%)\n",
            "    Runner-up: D4 (Confidence: 6.46%)\n",
            "Chunk (Readings 9420 to 9599):\n",
            " ➡️ D5 (Confidence: 93.35%)\n",
            "    Runner-up: D4 (Confidence: 6.38%)\n",
            "Chunk (Readings 9480 to 9659):\n",
            " ➡️ D5 (Confidence: 92.90%)\n",
            "    Runner-up: D4 (Confidence: 6.80%)\n",
            "Chunk (Readings 9540 to 9719):\n",
            " ➡️ D5 (Confidence: 92.39%)\n",
            "    Runner-up: D4 (Confidence: 7.25%)\n",
            "Chunk (Readings 9600 to 9779):\n",
            " ➡️ D5 (Confidence: 92.90%)\n",
            "    Runner-up: D4 (Confidence: 6.78%)\n",
            "Chunk (Readings 9660 to 9839):\n",
            " ➡️ D5 (Confidence: 94.44%)\n",
            "    Runner-up: D4 (Confidence: 5.36%)\n",
            "Chunk (Readings 9720 to 9899):\n",
            " ➡️ D5 (Confidence: 94.82%)\n",
            "    Runner-up: D4 (Confidence: 5.02%)\n",
            "Chunk (Readings 9780 to 9959):\n",
            " ➡️ D5 (Confidence: 95.28%)\n",
            "    Runner-up: D4 (Confidence: 4.58%)\n",
            "Chunk (Readings 9840 to 10019):\n",
            " ➡️ D5 (Confidence: 95.29%)\n",
            "    Runner-up: D4 (Confidence: 4.57%)\n",
            "Chunk (Readings 9900 to 10079):\n",
            " ➡️ D5 (Confidence: 95.24%)\n",
            "    Runner-up: D4 (Confidence: 4.62%)\n",
            "Chunk (Readings 9960 to 10139):\n",
            " ➡️ D5 (Confidence: 95.35%)\n",
            "    Runner-up: D4 (Confidence: 4.51%)\n",
            "Chunk (Readings 10020 to 10199):\n",
            " ➡️ D5 (Confidence: 95.37%)\n",
            "    Runner-up: D4 (Confidence: 4.49%)\n",
            "Chunk (Readings 10080 to 10259):\n",
            " ➡️ D5 (Confidence: 95.40%)\n",
            "    Runner-up: D4 (Confidence: 4.47%)\n",
            "Chunk (Readings 10140 to 10319):\n",
            " ➡️ D5 (Confidence: 95.45%)\n",
            "    Runner-up: D4 (Confidence: 4.41%)\n",
            "Chunk (Readings 10200 to 10379):\n",
            " ➡️ D5 (Confidence: 95.44%)\n",
            "    Runner-up: D4 (Confidence: 4.42%)\n",
            "Chunk (Readings 10260 to 10439):\n",
            " ➡️ D5 (Confidence: 95.41%)\n",
            "    Runner-up: D4 (Confidence: 4.45%)\n",
            "Chunk (Readings 10320 to 10499):\n",
            " ➡️ D5 (Confidence: 95.42%)\n",
            "    Runner-up: D4 (Confidence: 4.44%)\n",
            "Chunk (Readings 10380 to 10559):\n",
            " ➡️ D5 (Confidence: 95.46%)\n",
            "    Runner-up: D4 (Confidence: 4.40%)\n",
            "Chunk (Readings 10440 to 10619):\n",
            " ➡️ D5 (Confidence: 95.47%)\n",
            "    Runner-up: D4 (Confidence: 4.39%)\n",
            "Chunk (Readings 10500 to 10679):\n",
            " ➡️ D5 (Confidence: 95.46%)\n",
            "    Runner-up: D4 (Confidence: 4.41%)\n",
            "Chunk (Readings 10560 to 10739):\n",
            " ➡️ D5 (Confidence: 95.45%)\n",
            "    Runner-up: D4 (Confidence: 4.41%)\n",
            "Chunk (Readings 10620 to 10799):\n",
            " ➡️ D5 (Confidence: 95.31%)\n",
            "    Runner-up: D4 (Confidence: 4.55%)\n",
            "Chunk (Readings 10680 to 10859):\n",
            " ➡️ D5 (Confidence: 94.15%)\n",
            "    Runner-up: D4 (Confidence: 5.66%)\n",
            "Chunk (Readings 10740 to 10919):\n",
            " ➡️ D5 (Confidence: 93.21%)\n",
            "    Runner-up: D4 (Confidence: 6.50%)\n",
            "Chunk (Readings 10800 to 10979):\n",
            " ➡️ D5 (Confidence: 93.36%)\n",
            "    Runner-up: D4 (Confidence: 6.35%)\n",
            "Chunk (Readings 10860 to 11039):\n",
            " ➡️ D5 (Confidence: 93.36%)\n",
            "    Runner-up: D4 (Confidence: 6.34%)\n",
            "Chunk (Readings 10920 to 11099):\n",
            " ➡️ D5 (Confidence: 93.18%)\n",
            "    Runner-up: D4 (Confidence: 6.52%)\n",
            "Chunk (Readings 10980 to 11159):\n",
            " ➡️ D5 (Confidence: 92.75%)\n",
            "    Runner-up: D4 (Confidence: 6.90%)\n",
            "Chunk (Readings 11040 to 11219):\n",
            " ➡️ D5 (Confidence: 91.82%)\n",
            "    Runner-up: D4 (Confidence: 7.71%)\n",
            "Chunk (Readings 11100 to 11279):\n",
            " ➡️ D5 (Confidence: 91.37%)\n",
            "    Runner-up: D4 (Confidence: 8.08%)\n",
            "Chunk (Readings 11160 to 11339):\n",
            " ➡️ D5 (Confidence: 91.21%)\n",
            "    Runner-up: D4 (Confidence: 8.22%)\n",
            "Chunk (Readings 11220 to 11399):\n",
            " ➡️ D5 (Confidence: 91.16%)\n",
            "    Runner-up: D4 (Confidence: 8.25%)\n",
            "Chunk (Readings 11280 to 11459):\n",
            " ➡️ D5 (Confidence: 91.17%)\n",
            "    Runner-up: D4 (Confidence: 8.23%)\n",
            "Chunk (Readings 11340 to 11519):\n",
            " ➡️ D5 (Confidence: 91.14%)\n",
            "    Runner-up: D4 (Confidence: 8.27%)\n",
            "Chunk (Readings 11400 to 11579):\n",
            " ➡️ D5 (Confidence: 91.18%)\n",
            "    Runner-up: D4 (Confidence: 8.23%)\n",
            "Chunk (Readings 11460 to 11639):\n",
            " ➡️ D5 (Confidence: 91.30%)\n",
            "    Runner-up: D4 (Confidence: 8.13%)\n",
            "Chunk (Readings 11520 to 11699):\n",
            " ➡️ D5 (Confidence: 92.85%)\n",
            "    Runner-up: D4 (Confidence: 6.74%)\n",
            "Chunk (Readings 11580 to 11759):\n",
            " ➡️ D5 (Confidence: 95.25%)\n",
            "    Runner-up: D4 (Confidence: 4.60%)\n",
            "Chunk (Readings 11640 to 11819):\n",
            " ➡️ D5 (Confidence: 95.38%)\n",
            "    Runner-up: D4 (Confidence: 4.48%)\n",
            "Chunk (Readings 11700 to 11879):\n",
            " ➡️ D5 (Confidence: 95.65%)\n",
            "    Runner-up: D4 (Confidence: 4.22%)\n",
            "Chunk (Readings 11760 to 11939):\n",
            " ➡️ D5 (Confidence: 95.69%)\n",
            "    Runner-up: D4 (Confidence: 4.18%)\n",
            "Chunk (Readings 11820 to 11999):\n",
            " ➡️ D5 (Confidence: 95.76%)\n",
            "    Runner-up: D4 (Confidence: 4.12%)\n",
            "Chunk (Readings 11880 to 12059):\n",
            " ➡️ D5 (Confidence: 95.50%)\n",
            "    Runner-up: D4 (Confidence: 4.37%)\n",
            "Chunk (Readings 11940 to 12119):\n",
            " ➡️ D5 (Confidence: 95.61%)\n",
            "    Runner-up: D4 (Confidence: 4.27%)\n",
            "Chunk (Readings 12000 to 12179):\n",
            " ➡️ D5 (Confidence: 95.72%)\n",
            "    Runner-up: D4 (Confidence: 4.16%)\n",
            "Chunk (Readings 12060 to 12239):\n",
            " ➡️ D5 (Confidence: 95.70%)\n",
            "    Runner-up: D4 (Confidence: 4.18%)\n",
            "Chunk (Readings 12120 to 12299):\n",
            " ➡️ D5 (Confidence: 95.69%)\n",
            "    Runner-up: D4 (Confidence: 4.19%)\n",
            "Chunk (Readings 12180 to 12359):\n",
            " ➡️ D5 (Confidence: 95.53%)\n",
            "    Runner-up: D4 (Confidence: 4.34%)\n",
            "Chunk (Readings 12240 to 12419):\n",
            " ➡️ D5 (Confidence: 95.63%)\n",
            "    Runner-up: D4 (Confidence: 4.25%)\n",
            "Chunk (Readings 12300 to 12479):\n",
            " ➡️ D5 (Confidence: 95.65%)\n",
            "    Runner-up: D4 (Confidence: 4.22%)\n",
            "Chunk (Readings 12360 to 12539):\n",
            " ➡️ D5 (Confidence: 95.55%)\n",
            "    Runner-up: D4 (Confidence: 4.33%)\n",
            "Chunk (Readings 12420 to 12599):\n",
            " ➡️ D5 (Confidence: 95.33%)\n",
            "    Runner-up: D4 (Confidence: 4.53%)\n",
            "Chunk (Readings 12480 to 12659):\n",
            " ➡️ D5 (Confidence: 95.06%)\n",
            "    Runner-up: D4 (Confidence: 4.80%)\n",
            "Chunk (Readings 12540 to 12719):\n",
            " ➡️ D5 (Confidence: 95.23%)\n",
            "    Runner-up: D4 (Confidence: 4.63%)\n",
            "Chunk (Readings 12600 to 12779):\n",
            " ➡️ D5 (Confidence: 95.74%)\n",
            "    Runner-up: D4 (Confidence: 4.14%)\n",
            "Chunk (Readings 12660 to 12839):\n",
            " ➡️ D5 (Confidence: 95.68%)\n",
            "    Runner-up: D4 (Confidence: 4.19%)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "# --- Constants for the test function ---\n",
        "SCALER_PATH = 'time_series_scaler.pkl'\n",
        "LABELS_PATH = 'freshness_labels.json'\n",
        "MODEL_TO_TEST = 'best_model.keras' # This is the model your training cell saved\n",
        "CHALLENGE_CSV = 'test dataset - Sheet1.csv' # The file you created in the cell above\n",
        "WINDOW_SIZE = 180\n",
        "STEP_SIZE = 60 # Using a smaller, overlapping step for a detailed view\n",
        "\n",
        "def evaluate_model_confidence(model_path, challenge_csv_path):\n",
        "    \"\"\"\n",
        "    Loads a trained model and evaluates it on the challenge CSV.\n",
        "    \"\"\"\n",
        "    print(f\"\\n🚀 Starting confidence test for: {model_path}\")\n",
        "\n",
        "    # --- 1. Load Helpers ---\n",
        "    try:\n",
        "        scaler = joblib.load(SCALER_PATH)\n",
        "        with open(LABELS_PATH, 'r') as f:\n",
        "            freshness_labels = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading helpers (scaler/labels): {e}\")\n",
        "        print(\"➡️ Make sure you have run your main training cell first!\")\n",
        "        return\n",
        "\n",
        "    # --- 2. Load the Model ---\n",
        "    try:\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "        print(f\"✅ Successfully loaded model and helpers.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading model '{model_path}': {e}\")\n",
        "        print(\"➡️ Make sure your main training cell has run and saved the model.\")\n",
        "        return\n",
        "\n",
        "    # --- 3. Load and Process Challenge Data ---\n",
        "    try:\n",
        "        live_df = pd.read_csv(challenge_csv_path)\n",
        "        print(f\"📄 Loaded '{challenge_csv_path}' with {len(live_df)} readings.\")\n",
        "\n",
        "        if len(live_df) < WINDOW_SIZE:\n",
        "            print(f\"❌ Error: Data is too short (need {WINDOW_SIZE} readings).\")\n",
        "            return\n",
        "\n",
        "        print(f\"--- Analysis (Window: {WINDOW_SIZE}, Step: {STEP_SIZE}) ---\")\n",
        "\n",
        "        # --- 4. Run Sliding Window ---\n",
        "        for i in range(0, len(live_df) - WINDOW_SIZE + 1, STEP_SIZE):\n",
        "\n",
        "            data_chunk = live_df[['MQ3', 'MQ8', 'MQ135']].iloc[i : i + WINDOW_SIZE]\n",
        "            live_data = data_chunk.values\n",
        "\n",
        "            scaled_data = scaler.transform(live_data)\n",
        "            scaled_data_batch = np.expand_dims(scaled_data, axis=0)\n",
        "\n",
        "            probs = model.predict(scaled_data_batch, verbose=0)[0]\n",
        "\n",
        "            # --- 5. Get Top Prediction ---\n",
        "            prediction_index = np.argmax(probs)\n",
        "            prediction_label = freshness_labels[str(prediction_index)]\n",
        "            confidence = probs[prediction_index]\n",
        "\n",
        "            # --- 6. Get Runner-Up Prediction ---\n",
        "            temp_probs = np.copy(probs)\n",
        "            temp_probs[prediction_index] = 0 # Zero out the top prediction\n",
        "            runner_up_index = np.argmax(temp_probs)\n",
        "            runner_up_label = freshness_labels[str(runner_up_index)]\n",
        "            runner_up_confidence = temp_probs[runner_up_index]\n",
        "\n",
        "            # --- 7. Print Results ---\n",
        "            print(f\"Chunk (Readings {i} to {i + WINDOW_SIZE - 1}):\")\n",
        "            print(f\" ➡️ {prediction_label} (Confidence: {confidence*100:.2f}%)\")\n",
        "            print(f\"    Runner-up: {runner_up_label} (Confidence: {runner_up_confidence*100:.2f}%)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An error occurred during analysis: {e}\")\n",
        "\n",
        "# --- RUN THE TEST ---\n",
        "evaluate_model_confidence(model_path=MODEL_TO_TEST,\n",
        "                          challenge_csv_path=CHALLENGE_CSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ObhH-fJ2_CSu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "6346afe0-f7f0-488b-9656-ac5aed593d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Loading model to generate report...\n",
            "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\n",
            "--- Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          D1       1.00      1.00      1.00      1005\n",
            "          D2       0.99      0.96      0.98       877\n",
            "          D3       0.96      1.00      0.98       849\n",
            "          D4       0.99      0.97      0.98       824\n",
            "          D5       0.98      0.98      0.98       768\n",
            "\n",
            "    accuracy                           0.98      4323\n",
            "   macro avg       0.98      0.98      0.98      4323\n",
            "weighted avg       0.98      0.98      0.98      4323\n",
            "\n",
            "\n",
            "--- Confusion Matrix ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "\n",
        "# --- SETTINGS ---\n",
        "MODEL_PATH = 'best_model.keras'\n",
        "CLASS_NAMES = ['D1', 'D2', 'D3', 'D4', 'D5'] # Make sure this order is correct!\n",
        "# ---\n",
        "\n",
        "print(\"🚀 Loading model to generate report...\")\n",
        "# Load the model, scaler, and labels\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "with open('freshness_labels.json', 'r') as f:\n",
        "    freshness_labels = json.load(f)\n",
        "\n",
        "# We need the y_test variable from your training cell.\n",
        "# If you get a \"y_test not defined\" error, re-run your main training cell.\n",
        "try:\n",
        "    # Get the model's predictions on the TEST set\n",
        "    y_pred_probs = model.predict(X_test_scaled)\n",
        "\n",
        "    # Convert probabilities to single class labels (e.g., [0.1, 0.9] -> 1)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    # Also convert the one-hot y_test back to single class labels\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # --- 1. The Classification Report ---\n",
        "    print(\"\\n--- Classification Report ---\")\n",
        "    print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
        "\n",
        "    # --- 2. The Confusion Matrix ---\n",
        "    print(\"\\n--- Confusion Matrix ---\")\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',\n",
        "                xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "except NameError:\n",
        "    print(\"\\n❌ ERROR: 'X_test_scaled' or 'y_test' not found.\")\n",
        "    print(\"Please re-run your main training cell to put them in memory, then run this cell again.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUd7crtkKu8S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOd/KNPO/RHacUF41Nd8d2A",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}